# AlphaGo 究竟知不知道围棋的规则

昨天听我同事讲电话提到了AlphaGo，他说“就像AlphaGo你也要先知道围棋的规则啊，然后再……”。我当时的第一反应就是这说的不对啊，AlphaGo主要利用增强学习的技术，它只需要知道棋盘上的状态并不需要知道围棋的实际规则比如**气、眼**什么的。因为对于它来说围棋更像是一个有着361个像素的黑白图，它需要知道的只是当前状态和下一个状态的图形到底是什么样子的，然后根据已经学习到的奖励分数把图像朝着收益最大的方向改变就行了。但是今早骑车又在脑子里仔细过了过这个问题才发现细思极恐啊。

首先我可以确定AlphaGo肯定不用像人一样首先教他什么是活棋什么是死棋，什么时候该提子，什么叫两个眼必活。但是它真的是一点规则都不需要知道吗？NO！我觉得还是必须有许多基本规则它是事先知道的，比如只能下在19*19的范围内、不能把一个子下到另一个子已经存在的地方。在AlphaGo的视野里棋盘就是它的世界，它在这个世界上的行动必须遵守一定的规则，这些规则是在科学家建立模型的时候就已经告诉它了，它在一个状态下的动作可以是哪些是有一个明确范围的，所以它一定不会走出棋盘也一定不会覆盖一个已经存在的子。那么从这个角度来说我同事说的“先知道围棋的规则”又是对的了。在AlphaGo的世界里其实就是361个点，每个点有三种状态**黑、白、空**，总共$3^{361}$种变化。我们每落一个子就会改变这个世界的状态，而AlphaGo就是通过它的“大脑”对这个新的状态做出一个动作，这个动作的目的就是要将最终赢棋的概率最大化。这里也揭示出了AlphaGo对于围棋何为赢何为输的规则一样是事先建立的，当然方式方法可能和我们人以为的有点不同。但是它必须知道这个规则否则就无法训练和迭代了。

最后我还想到了一个特殊的围棋规则**劫争**，因为当时李世石战的第二盘网上很多就说好像AlphaGo不会打劫。我就在想对于这个规则AlphaGo是如何知道的呢？如果说是根据训练的棋谱来的，也就是每一个任何一盘棋都不会在同一个地方不断打劫所以它也不会在这里重复，那这个应该只是一个概率问题。AlphaGo极大概率不会违反规则但是并不能一定保证它不会重复打劫。如果要完美解决这个问题我认为从增强学习的技术上来说可能会是这样的：对于每一次重复的劫争动作给予一个非常大的负反馈。这样AlphaGo就会在不断学习中避免这个违反规则的动作再发生了。当然这只是我的个人想法，究竟AlphaGo如果处理劫争还希望有高人可以指点。

所以到底AlphaGo知不知道围棋的规则呢？随你怎么说吧：）