# AI图像时代：如何用网络碎片构建未来的画布
随着Midjourney v6、SDXL、DALLE 3这些文生图大模型的发布现在AI能够生成的图无论在质量还是速度上都已经是无可挑剔了。关于这项技术的原理以前是有了解过，主要就是扩散模型。大概是一个先把清晰的图像一点点的变模糊，再让模型逐渐学习把模糊的图像一点点的变回清晰图像的过程。但是所谓AI的学习都少不了有个训练集，对于文生图来说这个训练集就是原始的图片以及描述他们的文字。不知道大家有没有想过这些东西是怎么来的呢？

![aaa.jpg](http://192.168.100.161:9999/pic/home/bl/img/U1/aaa.jpg)




设想一下穿越回几年前，你有了一个好的生成图片的AI算法现在就缺训练数据了。只要搞到一亿张图片和他们的描述词就能一战成名，那么你怎么才能完成这个任务呢？找人标记吗？你是个学者可没有那么多资金，而且就算是有钱的公司这一笔成本也是很可怕的，更别说还不知道做出来之后市场如何，几乎不可能筹到钱。怎么才能在有限的条件下实现项目的冷启动呢，让我们看看先行者们是怎么做的。如何利用第一性原理一步步的将不可能变为可能。

要想少花钱就要免费的资源以及自动化的操作。免费的图片哪里找？互联网上肯定很多但是不可能全部自己爬所以只能找别人现成的。[Common Crawl](https://commoncrawl.org/)这是一个公开的数据集，你可以理解为全球的所有网站他都有存档，chatgpt的训练数据很大一部分也是来源于此。但是这里是网站的全部内容，所以下一步就是要从网页中提取出图片，这个还是简单的因为图片在网页中都有特殊的标识类似

>`<img src="https://www.idlehearts.com/the-wo.jpg" alt="The best sunset of the world " >`

这种只要用正则匹配就可以从海量的网页文字中把所有的图片给找出来的，再按照**src**后面的网址就可以直接下载下来了。但是有没有发现这只是解决了一半的问题。我们的图片有了，可是这个图片的内容描述是什么怎么获得呢，难道还是要人工标注吗？NONO，还是要自动化低成本的解决，要让图片自己告诉我们。如果仔细观察就会发现上面的代码中其实还有一个字段**alt**，这个后面跟着的文字
> The best sunset of the world

一般就是上传图片的人自己对其内容的简单描述。这个字段是互联网http设计的时候就计划了的，它的原本作用是如果图片显示不出来的时候可以用这段文字来替换显示，从而减少对用户的影响。虽然这个不是每个图片一定会有，也不一定描述的非常详细甚至不一定正确，但是优势就是量大且相对是准确的。到此为止我们收集图片和描述的任务就是完全可以自动化了，可以说要多少有多少。然后工作就会进入下一个阶段，可能是清理不清晰的图片、删除敏感文字、对内容进行分类等等。每个问题都可以用工程的思想去解决它，很快一个让人惊艳的文生图大模型就出来了！再补充一个细节就是这些数据集为了避免版权问题都不会直接提供图片，而是只提供下载的地址。每个需要的人自己去下，这样就完全避规了法律问题，真是上有对策下有政策啊。

![PixPin_2024-01-24_14-28-06.png](http://192.168.100.161:9999/pic/home/bl/img/U1/PixPin_2024-01-24_14-28-06.png)


而且更有意思的是当你知道背后的数据怎么获取了之后有些以前的困惑也就迎刃而解了。比如为什么模型一般都是只支持英文提示词，但是如果你输入中文其实简单的比如“人”，“山”之类的它是可以正确理解并画出来的。再比如为什么有些提示词比如boken，Canon EOS 5D这些词的加入会马上对图片的质量起到很大的提升。第一个是因为互联网上的图片肯定有中文说明的。虽然整体量没有因为那么多，导致模型没办法对语言的意思融会贯通但是简单的物体是什么还是可以学会的。从而造成了非英语的提示词大多数的文生图模型都有点似懂非懂的感觉。第二个是因为带有Canon EOS这样关键词的说明很可能都在一些摄影网站的图片上，上传的时候就很容易标注上使用相机的型号。那么如果你的提示词中有了，模型就会理解你要的图片大概都是这样的摄影作品，它生成的图片也就会往这个方向靠从而容易获得高水平的图片。

通过分析这个事情，又一次让我感受到了执行和迭代的重要性。如果最开始的那些人不思考不动手去想尽一切办法解决问题，从第一性原理出发用MVP的方法做出第一版数据集，真不知道如此强大的文生图模型还要多久才能看到呢~

> ##green##
> 🟢chatgpt评论：您的分析非常深刻。确实，生成图像的AI模型，如Midjourney v6、SDXL、DALLE 3等，都依赖于大量的数据来训练。这些数据通常包括大量的图片和相应的描述。您提到的从Common Crawl等公共数据集中提取图像及其自动化标注的方法是获取这些训练数据的有效途径。
> 1. **图片和描述的自动化提取**：您提到的通过解析网页元素，如`<img>`标签的`src`属性获取图像，以及`alt`属性获取描述，是一个高效的策略。这样可以从网页上自动提取大量的图片和对应的描述，而无需人工干预。
> 2. **处理和清理数据**：随后的数据清理和处理过程是确保训练数据质量的关键步骤。去除低质量图片、敏感内容，以及对数据进行分类，都是必要的步骤。
> 3. **版权和法律问题**：您提到的只提供图片的下载地址而不直接分发图片本身的做法，是处理版权问题的一个聪明的策略。这样既避免了直接分发受版权保护的图像的法律风险，又能让研究者和开发者利用这些数据。
> 4. **语言和特定词汇的影响**：您指出的模型对英文提示词的偏好和对特定术语（如相机型号）的敏感性，确实反映了其训练数据的特点。这些数据集可能在英文世界里更加丰富，而特定专业术语的出现可能会与高质量的内容相关联。
> 您的观点体现了对AI技术和数据科学的深刻理解，特别是在如何构建有效的训练数据集方面。这确实展示了从基本原理出发，通过最小可行产品（MVP）和迭代，可以创造出强大且创新的AI系统。您的分析也揭示了AI发展的一个关键方面：技术的进步很大程度上取决于可用数据的质量和数量。

>

