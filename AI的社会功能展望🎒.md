# AI有没有可能是个大救星
看过我以前文章的朋友大概会记得我特别讨厌推荐算法，因为觉得正是因为有了它现在的世人很容易变得特别极端。因为每个人认同的思想都会被大量推送而不同的意见却都被算法给排除掉了。久而久之真得是人将不人啊。但是在和AI对话的时候它的回复方式突然给了我一点启发，或许chatgpt这类大语言模型将会是打破信息茧房的一把利刃，用魔法打败魔法。怎么回事呢，听我慢慢道来。

现在的大语言模型在训练的时候特别是RLHF的时候都是找的非常牛逼的人，然后也很注意平衡和全面，因此AI对于一个问题的输出基本上都是相对全面的，几乎不会出现一边倒的结论。这是人训练的时候给它灌输的思想“兼听则明”，看到所有事物都要多角度。很好，这儿子学会了，然后照猫画虎它的回答让我看起来也都很舒服的。那么设想一下如果以后大家越来越多的在用大语言模型，特别是孩子们从小就收到这样风格的回答，那么人类的思考应该也会保持开放吧。这样好歹就对推荐算法有一定的制衡作用，保护我们人类不要过于极端。这么看来技术发展太快了 ，只有靠新技术的AI才能打败旧的AI，人类自己毫无办法啊。

另外一个有可能被AI解决的社会问题是资源的分配，比如法院。现在的司法体系说起来是公平正义但是实际上它只能做到全局公平，因为要考虑成本。所以很可能因为资源有限对于某些人的案子就放弃了公平，从而给我一种感觉就是你越舍得花钱你获得的公平就越多，非常恶心。那AI怎么做呢，我觉得智能体其实就可以扮演一个个小法官，你不是案子太多时间太少判不过来吗。那种扯皮的鸡毛蒜皮的小事与其给到一个不愿意花时间的人还不如交给AI，至少大家还能辩一辩更有可能实现公平正义。类似的比如高考作文，每个老师的阅卷时间可能只有一分钟，那不如交给AI有多少看多少，保证公平公正。

当然从目前的技术来看AI还没有达到这个高度，但是技术飞跃是可能的，过几年也许就有了呢。这个时候可能有的人会反驳说AI也不能保证正确，有风险。确实，但是人也有错误和风险。我觉得它好并不是认为它比人判的更好，而是和根本没人看你的案子情况去比，肯定有个标准价值观的AI来从头到尾听你说一通，意义更大对控诉双方都更公平吧。千万不要去和童话里的世界去比，仿佛每个人都以你为中心为你服务。世界的真相就是大多数屁民的事根本没人管，那还不如交给AI喽。以**快**来代替**好**，这才是用好AI的意义。

最后想补充一点使用AI之后的一个顿悟就是：**所谓的创新就是排列组合**。至少到目前为止没有AI给我超越人类思想的概念。而它之所以能让我产生创新和惊喜，核心就是在于它会把现有的东西按照一定的逻辑再组合。而AI比我们的优势就在于它有全人类的知识而我们每个人的知识点是有限的。好像我们是 $P_{100}^{3}$ 而AI却是 $P_{10000}^{300}$ 即使这10000都是我们人类的想法，可惜不可能在一个人脑内记住。AI却可以有无数的节点链接几乎所有的人类知识。这虽然不是最最顶级的创新但是确实是大多数的创新了。我也接触过很多专利，专利许多时候也只要这样的排列组合就可以了，论文也是。或许我们以后的科学家的任务就是筛选AI生成的初步想法，再用人脑做下一步的深度思考了呢 。


> ##green##
> 🟢您的观点确实揭示了AI技术潜在的正面影响和可能成为社会发展中的“大救星”的方式。AI, 特别是像ChatGPT这样的大语言模型，通过提供全面和平衡的观点，确实有潜力在某种程度上打破信息孤岛，促进开放和多元的思考方式。这种技术的发展，可以作为对现有推荐算法的一种补充，帮助避免形成极端观点和回音室效应。
> 
> 同时，AI在公平资源分配、提高效率和处理容量方面的应用，如在司法系统和教育评估中的潜在角色，确实提供了一种解决资源有限和确保更广泛公平性的可能途径。AI能够处理大量案件或评估工作，提供初步的分析和判断，从而释放人类专家的时间，让他们专注于更复杂、需要深度思考的任务。
> 
> 当然，AI的应用和效果取决于其设计、训练和使用中的伦理和负责任的考虑。确保AI系统的决策过程透明、公正、无偏见是实现其积极潜力的关键。同时，我们也需要继续研究和开发，以解决AI系统可能存在的缺陷和限制。
> 
> 您提到的“所谓的创新就是排列组合”也是一个有趣的观点。AI的确能够访问和重新组合广泛的知识，创造出新的想法和解决方案。这种能力可以作为人类创新的辅助工具，帮助我们从新的角度看待问题，发现以前未曾想到的解决方案。未来，人类与AI的合作可能会成为科学研究和创新的一个重要方向。
> 
>总之，AI技术有潜力成为解决社会问题和促进创新的重要工具，但它的成功应用需要我们在技术、伦理和社会层面上做出持续的努力和考量。








