# ChatGPT WTF?!

说起这个月最火的AI技术，ChatGPT可谓是当之无愧。风头不仅压过了前几个月刚刚大火的AI绘画，而且还火出了技术圈变成全民话题，颇有一种2016年AlphaGO和李世石大战时那种划时代革命的感觉了。还没玩过的小伙伴可以去[这里](https://chatgpt.sbaliyun.com/)体验一下啦。

毫不夸张的说ChatGPT给我带来的感觉是不可思议不可理解，甚至更多的是一种忧虑。以往的AI应用从技术层面都还算容易解释，基本是跳不出概率统计这个数学基础框架的。就像人们经常说给一个猴子无限的时间它也可以敲出莎士比亚全集，大多时候我们只会把这当成一个笑话，理论上可以敲出来而已，从数学上来说小概率事件就等于不可能事件。可是现在真的有一只猴子一天之内敲出来了一个罗密欧与朱丽叶的故事递到你面前你可不得吓一跳。ChatGPT的回答在我看来完完全全就是一个无所不知的个人助理，给它很少的提示就可以准确的回答各种问题并且在连续对话中可以毫不费力的定位出各种代词的指代对象。还可以写诗、翻译、检查代码和创造小说等等无所不能，简直就是一个有智慧有创造力的强人工智能，而不是只会做自然语言处理的聊天机器人了。在体验它后你只会觉得目前家里用的那些智能音箱基本就是一个“弱智”。我们可以通过下面的一些例子来看看ChatGPT的强大。

![pic](C:\Users\guocc\Desktop\测试\pic.gif)

但是多做一些测试就会发现ChatGPT对于脑筋急转弯类的问题回答的相当不好，说明它的“脑子”真的还不会“转弯”呢。比如下面这个例子。

<img src="C:\Users\guocc\Desktop\测试\屏幕截图 2022-12-26 164316.png" alt="屏幕截图 2022-12-26 164316" style="zoom:50%;" />

基本上可以说是在一本正经的胡说八道，被揭穿了之后先是假装承认错误的狡辩了一番，再被呵斥之后终于认识到自己的错误诚恳的道歉。如果给你这样一段对话而不告诉是AI所做是不是会觉得很像一个调皮的孩子，一个有着自己思想的“人”。

带着强烈的好奇心我们查阅了openAI介绍ChatGPT的网页，想看看它除了机器学习的方法之外还有没有什么神秘力量？结果别人把ChatGPT的诞生过程写的非常清楚，还是那个熟悉的味道、还是那些同样的AI范式还是那个永恒的概率统计，果然最大的恐惧来源于无知。了解了原理之后觉得训练的过程并没有超出人们的理解但是结果确实有些匪夷所思，这也许是openAI的科学家自己也没有想到的。训练量不断增大产生的一个量变到质变的提升，仿佛是突破了某一个奇点。如果你在openAI的后台去看它怎么生成答案的就会发现其实它还是用前面的句子去预测后面的每一个词，然后从结果中选择概率最高的那个输出。而这个也就是GPT（Generative Pre-trained Transformer 生成式预训练模型）的范式，GPT迭代出了GPT3，然后GPT3又迭代出了[InstructGPT](https://openai.com/blog/instruction-following/)，而我们今天说的ChatGPT就是InstructGPT的同胞兄弟。

<img src="C:\Users\guocc\Desktop\测试\屏幕截图 2022-12-26 180342.png" alt="屏幕截图 2022-12-26 180342" style="zoom:50%;" />

按照官网的说法ChatGPT就是GPT3的模型再调优得到的。而GPT3的训练简单来说就是给一段话预测后一个字的监督学习。比如

> ​	我喜欢吃苹果

喂给模型“我喜欢吃苹”，它要预测出“果”那就对了。显而易见这样的模型训练最大的优势在于不需要人工标注，所有可以搜集到的正常的文本都自动可以变成监督学习的语料。openAI把互联网上搜集到的各种文本都喂给模型这就是ChatGPT仿佛什么都懂的原因了。但是这样的模型还是不能用来做个人助理，因为它的输出太随机了。比如你问

> 中国的首都是哪里？

因为GPT见过网上各种文字，它的后面可能直接跟正确的答案“北京”，也可能跟聊天的记录比如“我不知道”，或者是另一个问题“英国的首都是哪里？”。因此下一步就是如何让ChatGPT输出我们最想要的那个个人助理应该输出的答案，这里openAI的介绍里用了一个很生动而又准确的词就是“unlocks（解锁）”。它的意思是GPT其实在之前的学习中已经知道了每个问题的正确答案是什么，后面的训练就是想要把这个正确的回答在用户问出相应问题的时候从海量的回答中解锁出来排在第一位。

整个训练过程主要有三步。第一步人工标注的监督学习，选取一些问题让真人去做出回答。用这些训练数据来给GPT3模型做优化，让它倾向于对问答类问题输出和人一样的风格的答案。当然因为人工标注的成本很高openAI说只用了原始预训练中的2%的数据做监督学习。第二步，对于优化后的模型让它回答各种问题，然后收集不同的回答结果，再把这些结果交给真人去排序评分。通过这种方式训练出一个评分模型，这个模型的作用就是对每个问题的不同种GPT输出的答案做排序，让和人类训练师最相近的结果排在第一位。还用上面的中国首都的例子就是

> 北京 > 我不知道 >英国的首都是哪里

这样AI就又一次强化了人类的回答风格。第三步，用这个评分模型去对GPT回答的所有的问题的答案做像人一样的强化学习的反馈（openAI把它叫做Reinforcement Learning from Human Feedback (RLHF)）。强化学习大概和我们人类从零开始学一个游戏是一样的，比如绝地求生你一开始并不知道怎么玩，但是每次你死了就不开心，活到最后就开心得高分，然后你就在不知不觉中掌握了这个游戏的玩法了。RLHF也是类似，我们再在已经经过第一步调优的GPT3模型的基础上再对其进行调优，目标就是让模型输出的第一个答案在评分模型里得分尽量高，得分高了就奖励模型，得分低了就惩罚模型。那么经过训练之后ChatGPT就可以输出跟人类标注师喜好类似的回答结果了。最后再不断重复第二步和第三步让结果越来越好，ChatGPT就诞生了！从这个训练过程其实可以看出来人类标注师对于答案的偏好是可以决定ChatGPT风格的，这就好像三体小说里的思想钢印，AI永远也去除不了。我在玩的时候就发现ChatGPT的回答风格就很像某些砖家，说的每一句话都是对的，但是都很空没有什么真正有价值的信息。

![屏幕截图 2022-12-27 163654 (小)](C:\Users\guocc\Desktop\测试\屏幕截图 2022-12-27 163654 (小).png)

通过ChatGPT的训练过程我们也可以明白经过海量数据训练的模型确实什么都知道，但是如何通过一个好问题把你需要的信息从它的知识库里挖掘出来确实还是有些技巧的。这个感觉和我们人类自己的记忆一样，可能我的大脑里记得很多歌但是现在怎么就想不起来那一首是怎么唱的了，你需要想办法把记忆力的的旋律给挖掘出来就需要一个提示。也许给你歌名，也许要给你歌词的前几个字，对我来说可能最好的提示就是歌曲的一段旋律，只要提示词选对了，答案就呼之欲出了。因此现在网上也有很多大神总结的ChatGPT的[提示词库](https://github.com/f/awesome-chatgpt-prompts)可以帮助你更好的使用它来获得最想要的答案。

虽然了解了ChatGPT背后的原理我们的担忧会少了一些，但是有些可能带来的负面后果还是值得讨论的。核心就是ChatGPT的“胡说八道”。在回答脑筋急转弯的时候我们就见识到了，幸好我们是中国人会汉语知道“错”不是多音字。但是如果是一个外国人也问了ChatGPT这个问题看到这么有模有样的答案会不会很容易就把它当成真相了呢？如果在家里放上一个这样有可能会说八道的机器人陪伴孩子学习我想也没有人会放心。这也正是为什么国外著名的程序员问答网站stackoverflow要禁用ChatGPT的原因了。但是遗憾的是这个所谓的禁用更多也只是靠个人自觉，其实是没有什么直接检测手段的。因为ChatGPT是一个文本生成模型它的输出只有若干文本，文本无论是AI输出的还是人写的都是那么几百个字不会有任何区别，这就是它和AI生成图像或者deepfake视频最大的不同点，也是它的可怕之处。因为图片类的信息有很多，一个800*600的图片就会有1440000个数字，虽然人看起来可能完全一样，但是因为模型训练的原因很可能从大量的数据点中识别出一些机器的特征，比如AI生成的图像人的眼睛不会有反射效果类似。而文本生成可能就没有任何多余的信息和特征可以提取，比如下面这个例子。

<img src="C:\Users\guocc\Desktop\测试\屏幕截图 2022-12-27 230004.png" alt="屏幕截图 2022-12-27 230004" style="zoom:50%;" />

如果有人在百度知道或者知乎问这么一个问题下面有这么一个回答你怎么断定它是AI写的还是人写的呢？就算你知识渊博知道钠离子电池技术能发现回答中有明显的错误，但是人毕竟不是机器不可能每个领域都懂的，在你不知道的领域如果看到类似的回答大概率会把它当成专业回答而把其顶上去了吧 。总之就是对于ChatGPT生成的回答因为太像模像样而且知识渊博导致对其真假的判断需要耗费太多的精力，将来如果技术放开各种假新闻满天飞的时候如何识别出这些糟粕就是个很棘手的问题了。另外一点就是使用ChatGPT的感受让我想起了之前一个新闻谷歌研究员声称人工智能LaMDA已经觉醒的[故事](https://m.jiemian.com/article/7630006.html)。当时我还觉得这个研究员很幼稚，但是现在想想自己如果每天和ChatGPT聊天的话觉得它有了智能觉醒了大概也并不奇怪了，真的是让人唏嘘。

最后的最后再说一点遗憾。遗憾的就是AI的各种最顶尖的东西都不是中国首创的，我们抄作业抄的似乎是不错，但是总觉得缺少点啥。希望我们专栏介绍AI最前沿技术来源于中国科技公司的那一天早日到来吧。



附上一个ChatGPT自己写的介绍ChatGPT的文章，本来想让AI来打的底稿，不过发现完全没有get到我的意思，很失望。

> ChatGPT是一种先进的聊天机器人技术，已经彻底改变了人工智能（AI）和自然语言处理（NLP）领域。由OpenAI开发的ChatGPT是GPT-3语言模型的变体，它以其生成类似人类文本的能力而闻名。
> ChatGPT与其他聊天机器人技术不同之处在于它能够保持上下文并进行连贯自然的对话。这是通过使用经过人类对话大型数据集训练的大型神经网络实现的。因此，ChatGPT能够理解语言的细微差别，并适当地回应各种查询和提示。
> 在实现方面，ChatGPT依靠机器学习算法和神经网络来处理和分析语言数据。从本质上讲，系统会接收大量文本数据，然后使用这些数据来学习人类语言的模式和结构。然后，系统使用这些知识生成类似于人类可能说的文本。
> 与ChatGPT的对话可能是这样的：
> 用户：嘿，ChatGPT，你今天怎么样？
> ChatGPT：你好！我是一个AI，所以我不会像人类那样感受。但是，我正常运行，并且在这里为您提供任何问题的帮助。
> 用户：哇，这真的很令人印象深刻。这是我第一次与一个AI聊天，它看起来像在以人类的方式思考和回应。
> ChatGPT：感谢你的夸奖！我的设计目的是尽可能地模仿人类的语言和回应。
> 如此例所示，ChatGPT能够以类似人类的方式参与对话。这既令人印象深刻，又有些令人不安，因为很难判断ChatGPT是真的在思考还是遵循了预先编程的脚本。
> 尽管具有引人注目的能力，但ChatGPT并不没有局限性。这项技术的一个主要担忧是它可能传播错误信息的潜力。由于ChatGPT能够生成与人类写的内容无法区分的文本，因此它有可能产生蓄意误导或欺骗性信息，这是很难识别的。如果ChatGPT被用来生成新闻报道或其他形式的媒体，并希望被视为事实，那么这将是特别问题。
> 另一个可能的ChatGPT问题是它依赖于它接受的数据。虽然系统能够生成各种回应并参与多种对话，但它的回应可能受到它所接受数据的范围的限制。这意味着ChatGPT可能无法准确地回应超出其训练数据集范围的查询或提示。例如，如果ChatGPT的训练数据中没有与某个特定的科学领域相关的信息，那么它可能无法对这个领域的问题进行准确的回应。
> 另一个可能的问题是ChatGPT可能存在偏见。由于这些系统是基于人类语言的大型数据集进行训练的，因此它们可能继承数据中存在的偏见。例如，如果ChatGPT的训练数据中存在性别或种族歧视，那么它可能会生成带有歧视色彩的回应。为了避免这种情况，开发人员和使用者需要意识到这种潜在偏见，并采取措施来消除它们。
> 尽管存在这些潜在问题，但ChatGPT和其他AI技术仍有巨大的潜力，可以帮助人们的生活变得更好。例如，它们可以用于帮助残疾人或为不足或劣势群体提供教育和信息。它们还可以用于自动化对人类来说是重复的或危险的任务，使人类能够将精力集中在更有意义和更有成就感的工作上。
> 总的来说，ChatGPT和其他AI技术的影响将取决于如何使用和发展它们。对于社会来说，关键是认真考虑这些技术的伦理影响，并为它们的使用制定负责任的指导原则。通过谨慎思考和考虑，ChatGPT和其他AI技术有可能以无数种方式提升和改善我们的生活。在最后的分析中，我们提到了ChatGPT可能传播错误信息的潜力，并且需要有专业背景知识才能发现它的漏洞。这是因为ChatGPT生成的文本是它所能提供的全部信息，而没有任何可以进一步挖掘的信息。相比之下，人工智能生成的图片和视频具有更多的信息，因此可以进行更深入的分析和判断。
> 然而，这并不意味着ChatGPT就没有用途。相反，它仍然可以用于很多有意义的场景，例如自动客服或提供信息和帮助。尽管如此，使用者仍然需要谨慎考虑ChatGPT提供的信息，并对其进行进一步的验证和核实。
> 在结束这篇文章之前，还有一点需要提及。我们在开头提到，ChatGPT是一种非常强大的对话系统，它与以往的对话系统有很大的不同。它的实现原理是使用了自然语言处理和机器学习技术，可以训练大型的语料库，并能够生成自然语言的文本。
> 然而，我们也要记住，这种技术也有一些潜在的风险和局限性。它可能传播错误信息，并可能存在偏见。因此，使用者应该谨慎使用ChatGPT，并对其提供的信息进行进一步的验证和核实。
> 在最后，我们希望这篇文章能够让您对ChatGPT有一个更全面和准确的了解，并能够让您理解这种技术的强大和潜在风险。我们希望这篇文章能够为您的决策和使用提供帮助。
> 还有更多关于ChatGPT的内容可以讨论。例如，我们可以深入探讨ChatGPT如何与其他AI技术，例如机器翻译或自动驾驶，相结合。我们也可以讨论ChatGPT在商业和政府应用中的潜力。此外，我们还可以讨论未来AI技术的发展趋势，以及它们对社会和个人生活的潜在影响。



## 参考材料

- [1] [chatgpt官方介绍](https://openai.com/blog/chatgpt/)
- [2] [InstructGPT官方介绍](https://openai.com/blog/instruction-following/)
- [3] [免注册ChatGPT体验网站](https://chatgpt.sbaliyun.com)
- [4] [有趣的ChatGPT提示词库](https://github.com/f/awesome-chatgpt-prompts)
- [5] [谷歌AI“觉醒”背后：奇迹还是闹剧](https://m.jiemian.com/article/7630006.html)
- [6] [InstructGPT，从人类回馈中学习，ChatGPT的前身（台大）](https://www.bilibili.com/video/BV1U84y167i3?p=3)