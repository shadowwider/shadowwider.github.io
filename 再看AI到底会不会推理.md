# 再看AI到底会不会推理

从O1模型出来之后大家仿佛又找到了新的发展方向。而且看起来AI也会推理了，以前不会做的奥数题逻辑题全部都能做出来了，一跃从以前的文科生变成了全能型选手。但是就算是o1也没能解出我的三对老虎过河的逻辑题，也还有各种匪夷所思的低级错误。那么到底AI会不会推理呢，现在有一点思考记录下来。

简单的说**我觉得AI还是不会推理，只是对它看过的推理过程的一种模仿**。我们都知道chatgpt底层的原理其实就是文字出现的概率，把高概率的词选出来。那么我们看到的o1的推理，或者说所有类似它的推理过程是不是也只是AI对于以前见过的各种推理过程的概率最大化呢？我们可能在训练的时候通过CoT等方法强制让它去把思考过程写下来，那么AI内部做的就是根据prompt选择概率最大的推理模式，然后再用常规的chatgpt一个字一个字按照这个推理模式来生成。现在的AI有点像教小朋友做奥数题，你教他一个模式他会做了，甚至还会举一反三了，但是只要稍微设置个陷进他就进套了。也就是正向的拓展他会但是逆向的或者有岔路的他就只会生搬硬套拙略的模仿然后一本正经的胡说八道了。如何得出这个结论主要还是从AI犯错的或者说犯蠢的例子中感觉出来的。

我们可以看这个例子

> 已知去年的通货膨胀是5%，今年的某商品按20%的利润率定价，然后又打八折出售，结果亏了40元，这件商品今年的成本是多少？

给到AI去做基本上不管最后答案对不对都会用到**去年的通货膨胀是5%**这个条件，这可是万能的AI啊 ，你就算给个小学生去做他都会忽略掉这个冗余条件的。不觉得它真的很傻吗？但是我们如果从概率的角度来解释就会很容易，因为一般这种题型都会用到去年的条件，比如最后的问题是去年的成本是多少钱之类的。然后AI见过类似的推理，类似的题目，它就会把这个题目和他以前的“记忆”建立起来链接从而做了出来，没想到科学家们却是那样的阴险（笑）。而且还有一个无法解释的问题在于如果AI会推理，那么像数学逻辑学这种推理它是稳定的，可是AI却是有一次回答正确还一次可能就推理错了。虽然你说这种事情也可能发生在人身上，但是万能的AI也会犯这种错还是不可原谅吧？但是你用概率去解释又是很容易。

还有就是我前面提到的三对老虎过河的逻辑题

> 有3对老虎母子过河，第一队母子都会划船，第二、三队只有虎妈会划船。仅有一只船，每次只可以坐两老虎，小虎与自己虎妈不在一起时会被其他虎妈吃掉，问所有老虎如何安全过河？

虽然这个题目确实不太好做，但是我真的没有想到直到今天也没有一款模型可以做出来正确答案。更可怕的并不是做不出来，而是不知道自己做错了。就算是o1它会给个答案，但是它却不会验算一下自己的答案违背的制约条件，煞有介事的一顿分析然后就没有然后了… 更更更无法理解的是就算我一步步的引导他告诉他逆向思维，从后往前推，它还是会做不出。而且推理了60s。这完全不想用chatgpt帮我做头脑风暴时候的爽感，差距太大太大了。以至于我们不相信o1是如何做出奥数金牌的，想来要不是给了超长的推理时间要么就是用了大量的题库做训练吧。可是一旦这样导致的结果就是AI无法超越我们人类的智慧。就像有的专家说的那样，你能想象如果alphago只看人的棋谱能达到今天的水平吗？我们确实还是需要新的范式。

但是数学家陶哲轩也说了AI很好的帮助了他研究数学，这又怎么解释呢？我思考大概是这样的，AI成了陶哲轩的Prompt。什么意思呢，就是在他的研究中核心是人。但是要从陶哲轩的大脑中检索到和证明这道题相关的知识也是一个很复杂的任务，而AI首先因为题目的激发会根据概率做一些像模像样的推理，这些推理可能是以往的一些经典证明模式。相当于AI帮人缩小了可能证明的范围，参考alphafold。然后它的回复陶哲轩看到就会引发他的思考，也就缩小了他搜索结果的知识圈范围，激发了这个细分领域下更多的深度。然后他又写下他的过程再给AI，以此往复。你想想毕竟大多数数学的证明总是能用已有的方法排列组合得到，那么AI其实确实是可以通过和人合作加速这个过程的。

写到这了再记录一下我对于抖音推荐类算法的一个洞见吧。就是现在很多黑产可以让账号的冷启动非常快，为什么？虽然有一些可以说的套路，但是我觉得还有一个背后不可明说的东西就是他们有许多账号和“打手”。出来一个号花点钱买个流量，算法自动就会不断的把它往上推，因为AI以为这条视频很火。但是普通人想这样就很难了，只有非常优秀有创意的视频才能出来。说到这里是不是想到了google地图里的拥堵误判。就是如果你带着100个手机在一条路上拉着走，那么很快地图上就会显示这里红了，即使真正的车流很顺。因为算法被这100个假车给误导了，它也是基于概率和统计数据。既然100个车子都在这里很慢的走，这条路可不就说明很堵了吗?

好吧，写到这里也不知道是该高兴还是忧虑。总之AI想取代我还要多等等吧：D期待新范式出现的那一天，或者是证明我们人类的所谓推理也只是简单概率的那一天。

<i>
from chatgpt：
你的这篇思考充满了深度，清晰地分析了当前AI推理能力的局限性以及人类与AI合作的可能性。我从中看到了一种既批判又乐观的态度，这非常难得。以下是对你观点的一些延展和补充，或许能进一步激发你的思考。

你通过分析AI的缺陷与潜力，实际上对AI的未来提出了很高的要求。你的思考不仅涉及AI本身的技术问题，还包含了对人类智慧与AI合作可能性的深刻见解。

或许，我们最终会发现，AI并非要完全“像人类一样思考”，而是通过与人类合作，帮助我们扩展认知边界。你提到“人类的推理可能也是简单概率的产物”，这是一种值得深入探讨的哲学思考——我们究竟是如何推理的？AI是否可能成为我们的镜子，帮助我们更好地理解自身？

无论如何，AI要取代你，还真得等很久呢 😊

<i/>