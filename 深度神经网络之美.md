# 深度神经网络之美

深度神经网络顾名思义就是具有很多层的[神经网络](https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)，而神经网络就是一种模拟人脑神经元工作的计算机模型。从它的起源来说最早其实是用来解决分类问题的，和一般的逻辑回归算法一样。但是现在随着计算力的发展以及越来越多的人不断的研究和创新，现在的深度神经网络（DNN）早已升华到一个前所未有的高度了。

我们先来看看DNN一开始是如何用的。首先它需要输入一组信息，然后通过对每个节点做最简单的线性变换构建新的一层，并不断的重复类似的动作，最后可能通过一个非线性的分类函数比如softmax方法把这一组信息映射到一个结果上。这样就实现了我们现在手机照相功能经常能看到的人脸识别功能了。这种分类功能当然有用，但是我觉得DNN之美并不仅仅在于此。人类智慧以从未有过的集中度钻研到这个领域中后其实诞生了许许多多神奇的结果，比如去年流行的[Primsa](https://prisma-ai.com/)。

初次见到Primsa我想许多人都被它的功能惊呆了，一个手机app居然可以把随便一张生活照转变成一幅极其具有大师风格的艺术作品。其实它的背后用到的也就是DNN，今天我就简单介绍一下它的原理。严格的说Primsa用的是DNN的一个分支**[卷积神经网络](https://zh.wikipedia.org/zh-hans/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)**（CNN），在模型上它并没有什么创新，或者说它本就是拿别人已经训练好的VGG模型来用的，但是在最终结果的实现方式上确实极具创意的，是真正的对DNN的一种深度应用。我们之前说过DNN的本质是分类，但是你直观的想想这种照片的艺术化并不太像一个分类问题，更像是一个转化的问题。我们的目的是让计算机生成一张新的图片，这张新的图片它的内容要像我们的原始图片，但是它的风格要像我们的风格图片。CNN的神奇之处就在于它通过每一层可以学习到图片的不同结构纹理等特征信息，也就是说如果我使用一个已经训练好的CNN模型我就可以把任何一张图片分解开来，把它的风格数字化；另一方面任何一张原始图片在计算机看来也就是一个矩阵，让两张图片相似我们可以简单的理解让这两个矩阵的每一个点的数值都尽量靠近，这里我们可能需要一个平方差求和。现在我们先生成一个随机的白噪声图片，它很像我们以前看电视没信号时的那种雪花点，然后我们利用机器学习的思想对它进行迭代更新，而这个更新的目标就是让下一代的图片它的风格数字化尽可能的靠近风格图片的风格数字化结果，而内容的点的值尽可能的靠近原始图片。用数学公式来表示就是
$$
L_{total} = \alpha L_{style} + \beta L_{content}
$$
最后我们输出的就是在这样的约束条件下综合误差最小的一张图片了，也就是Primsa上展示的各种艺术化图片了。而且还可以注意到上面式子中的$$\alpha$$ ,$$\beta$$ 其实是两个系数，分别表示风格相似度、内容相似度的权重，正因为这两个系数所以你才可以随意的在应用中调整图片风格的百分比，它里面的100%就是风格权重比较小的时候，而0%对应着内容权重比较小。所以如果掰开了揉碎了看，这个应用与其说是利用CNN还不如更准确的说是利用了CNN的一个创新的机器学习最优化模型，它里面有着机器学习的所有核心思想比如代价函数、梯度下降等等。这才是我觉得DNN最美的地方，它不是一个被热炒的概念，而是真正可以被用来改变我们的世界，让许多原本不可能的事情变成现实。

对于大多数非ML专业研究领域的人来说DNN更应该是一种工具或者一种思维方式。我们并不需要去关心如何优化模型让他们更准确或者效率更高，我们只需要把它已有的成果带入到我们自己熟悉的那个领域，通过自己的智慧创造出新的功能。比如我们做现金流的，利用同样的思想也许以后我们可以推出一个银行对账单模拟的功能，在你的公司100个人的时候给看看如果你扩张到10000个人那么你的银行流水将是个什么样子。或者网上一直很火的武侠小说段子古龙化、金庸化。我随便拿一个作家的武侠小说通过一个模型变换立刻可以给你呈现出金庸的风格。当然文字这类东西现在还没办法做的那么好。毕竟和艺术图片不同，它不具有什么容错性。可能仅仅是两个字顺序的颠倒我们就觉得不能看懂了，这也是目前机器翻译结果让人觉得不那么好的主要原因。上面说到机器翻译，其实像现在最新的机器翻译语音识别等技术也是一种对DNN的灵活运用而不仅仅是简单的分类。就比如语义识别的核心——词嵌入技术。它的目标是把我们的词典的每一个词变成一个有意义可以计算距离的多维向量。它虽然也是训练了一个DNN但是最后真正有用的并不是分类的结果，而是达到分类结果这个模型中某一层的参数矩阵。也就是说它也是利用了DNN的思维模型来解决传统语义识别中的一个问题。也正是这些实际的应用让我觉得虽然DNN本身有很多黑盒的特性人类还没有完全解释清楚，但是却并不会妨碍我们现在就使用它来改变世界，就像虽然量子世界的许多知识对于我们还是黑盒但是却并不妨碍几百年前的人类就用牛顿定律去研究由量子构成的星体的运动规律了。

思考、创新。人工智能+，我们来了！